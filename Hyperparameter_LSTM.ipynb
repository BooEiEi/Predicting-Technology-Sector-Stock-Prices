{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOJCQUt7cNe+WcsuSPfOsRh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BooEiEi/Predicting-Technology-Sector-Stock-Prices/blob/main/Hyperparameter_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8MaZhlDrtcR",
        "outputId": "526a5a0b-e4cc-4811-b92d-c14d47507c60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os# os ใช้จัดการกับไฟล์ ว่าอยู่ที่ไหน\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive #เชื่อม Google drive\n",
        "drive.mount('/content/drive')\n",
        "path_DF = '/content/drive/My Drive/master project/data/DF4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9jOL5oCa0GV",
        "outputId": "f458d60f-23d7-4c1c-e18d-583ab8137d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn version: 1.6.1\n",
            "tensorflow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "#import scikeras\n",
        "import tensorflow\n",
        "\n",
        "print(\"scikit-learn version:\", sklearn.__version__)\n",
        "#print(\"scikeras version:\", scikeras.__version__)\n",
        "print(\"tensorflow version:\", tensorflow.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HknQOqMRub22",
        "outputId": "4184880c-61c0-4432-df7e-052a512500af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scikit-learn 1.6.1\n",
            "Uninstalling scikit-learn-1.6.1:\n",
            "  Successfully uninstalled scikit-learn-1.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall scikit-learn -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-XK7G7OsZXI",
        "outputId": "dda2307b-978a-474f-e66f-32cff05c01ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.5.2\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\n",
            "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-1.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn==1.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWhaPENiwwPB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os._exit(00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5-m4h6Qw9he",
        "outputId": "d99b1e0f-69eb-44b5-e8cc-6479a5a508c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hnf04qw0EY-V"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dense, Flatten, LSTM, Bidirectional, Input, Dropout, InputLayer, BatchNormalization\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gG9YiElc_7kz"
      },
      "outputs": [],
      "source": [
        "df_META = pd.read_csv(os.path.join(path_DF, 'df_META.csv'))\n",
        "df_AAPL= pd.read_csv(os.path.join(path_DF, 'df_AAPL.csv'))\n",
        "df_MSFT= pd.read_csv(os.path.join(path_DF, 'df_MSFT.csv'))\n",
        "df_NVDA= pd.read_csv(os.path.join(path_DF, 'df_NVDA.csv'))\n",
        "df_GOOG= pd.read_csv(os.path.join(path_DF, 'df_GOOG.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uSTDB5B9ugYP"
      },
      "outputs": [],
      "source": [
        "df_META=df_META.drop(['Unnamed: 0'], axis=1)\n",
        "df_META['date'] = pd.to_datetime(df_META['date'])\n",
        "df_META = df_META.sort_values('date').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "djQalIUbey2Z"
      },
      "outputs": [],
      "source": [
        "df_AAPL=df_AAPL.drop(['Unnamed: 0'], axis=1)\n",
        "df_AAPL['date'] = pd.to_datetime(df_AAPL['date'])\n",
        "df_AAPL = df_AAPL.sort_values('date').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "phlW5GTCey2Z"
      },
      "outputs": [],
      "source": [
        "df_MSFT=df_MSFT.drop(['Unnamed: 0'], axis=1)\n",
        "df_MSFT['date'] = pd.to_datetime(df_MSFT['date'])\n",
        "df_MSFT = df_MSFT.sort_values('date').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6W6ztoJuey2Z"
      },
      "outputs": [],
      "source": [
        "df_NVDA=df_NVDA.drop(['Unnamed: 0'], axis=1)\n",
        "df_NVDA['date'] = pd.to_datetime(df_NVDA['date'])\n",
        "df_NVDA = df_NVDA.sort_values('date').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LQ9DvJ_Dey2Z"
      },
      "outputs": [],
      "source": [
        "df_GOOG=df_GOOG.drop(['Unnamed: 0'], axis=1)\n",
        "df_GOOG['date'] = pd.to_datetime(df_GOOG['date'])\n",
        "df_GOOG = df_GOOG.sort_values('date').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ag8q6iyhqdaZ"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(df_META) * 0.75)\n",
        "test_size = len(df_META) - train_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzFoELkSpPNh"
      },
      "source": [
        "# META"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKO1AFez3JBl"
      },
      "source": [
        "## Train Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iMokZmc2qCHc"
      },
      "outputs": [],
      "source": [
        "train_META = df_META.iloc[:train_size]  # ข้อมูล train\n",
        "test_META = df_META.iloc[train_size:]  # ข้อมูล test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88dfBz183N0n"
      },
      "source": [
        "### Train Varidation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z2-SLTebqAfX"
      },
      "outputs": [],
      "source": [
        "X_META = train_META[[\"S&P500\",\"CPI\",\"Interest\",\"US_inflation_rate\", \"NASDAQ\"]]\n",
        "y_META = train_META[\"Stockprice_META\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVb6YQjLaCaa"
      },
      "source": [
        "#Normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "os9nmxXNaGKo"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "X_META = scaler.fit_transform(X_META)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjuMKnVZhopE",
        "outputId": "2638cce8-ed7b-4276-bc1a-eec851bf0c68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "564"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_META.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QO9y5q6ddHuq"
      },
      "outputs": [],
      "source": [
        "look_back = 10\n",
        "\n",
        "X_META1, y_META1 = [], []\n",
        "for i in range(len(X_META) - look_back):\n",
        "    X_META1.append(X_META[i:i + look_back])\n",
        "    y_META1.append(y_META[i + look_back])\n",
        "\n",
        "X_META1, y_META1 = np.array(X_META1), np.array(y_META1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTFHcIMZdW_w",
        "outputId": "fba74fd3-7bdb-48b0-c20f-c0f26bc7237c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(554,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_META1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rly7WHfhf872",
        "outputId": "005a8342-f118-4de1-95d2-72b1e36dfd32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(554, 10, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_META1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WpmcaWbKJ8ac"
      },
      "outputs": [],
      "source": [
        "tscv = TimeSeriesSplit(n_splits=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_DEUG1fbJP4"
      },
      "source": [
        "#MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buw4unLOUqlh",
        "outputId": "3c0a0c59-083f-4758-f855-30eabbd31a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'batch_size': 16, 'epochs': 200, 'neurons': 256, 'optimizer': 'Adam'}\n",
            "Test Set Mean Squared Error: 165.7516\n",
            "Test Set Root Mean Squared Error: 12.8745\n",
            "Test Set Mean Absolute Error: 9.6628\n",
            "Test Set Mean Absolute Percentage Error: 0.0406\n"
          ]
        }
      ],
      "source": [
        "def create_model(neurons=16, optimizer='Adam'):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=neurons, input_shape=(look_back, X_META1.shape[2])))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "model = KerasRegressor(model=create_model,\n",
        "                       neurons=16,\n",
        "                       optimizer='Adam',\n",
        "                       verbose=0)\n",
        "\n",
        "\n",
        "param_grid = {'neurons': [16, 32, 64, 128, 256, 512],\n",
        "              'optimizer': ['RMSprop', 'Adam', 'AdamW', 'Nadam'],\n",
        "              'batch_size' :[16,32,64,128,256],\n",
        "              'epochs' :[60,80,100,150,200]}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs = -1)\n",
        "\n",
        "\n",
        "grid_result = grid.fit(X_META1, y_META1)\n",
        "\n",
        "best_model = grid_result.best_estimator_\n",
        "best_params = grid_result.best_params_\n",
        "\n",
        "y_pred = best_model.predict(X_META1)\n",
        "mse = mean_squared_error(y_META1, y_pred)\n",
        "rmse = root_mean_squared_error(y_META1, y_pred)\n",
        "mae = mean_absolute_error(y_META1, y_pred)\n",
        "mape = mean_absolute_percentage_error(y_META1, y_pred)\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Test Set Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"Test Set Root Mean Squared Error: {rmse:.4f}\")\n",
        "print(f\"Test Set Mean Absolute Error: {mae:.4f}\")\n",
        "print(f\"Test Set Mean Absolute Percentage Error: {mape:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOK2l4NYbGU-"
      },
      "source": [
        "#APPL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LEsjSeu9q6xD"
      },
      "outputs": [],
      "source": [
        "train_AAPL = df_AAPL.iloc[:train_size]  # ข้อมูล train\n",
        "test_AAPL = df_AAPL.iloc[train_size:]  # ข้อมูล test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "A8OkRpKIq6i8"
      },
      "outputs": [],
      "source": [
        "X_AAPL = train_AAPL[[\"S&P500\",\"CPI\", \"NASDAQ\"]]\n",
        "y_AAPL = train_AAPL[\"Stockprice_AAPL\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ULaIYhth8cQX"
      },
      "outputs": [],
      "source": [
        "X_AAPL = scaler.fit_transform(X_AAPL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kplx5WIvbmuc"
      },
      "outputs": [],
      "source": [
        "look_back = 10\n",
        "\n",
        "X_AAPL1, y_AAPL1 = [], []\n",
        "for i in range(len(X_AAPL) - look_back):\n",
        "    X_AAPL1.append(X_AAPL[i:i + look_back])\n",
        "    y_AAPL1.append(y_AAPL[i + look_back])\n",
        "\n",
        "X_AAPL1, y_AAPL1 = np.array(X_AAPL1), np.array(y_AAPL1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNM7Z2Yab2e_",
        "outputId": "61bd68db-9e34-4eff-9979-48391ee88f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'batch_size': 32, 'epochs': 200, 'neurons': 512, 'optimizer': 'Adam'}\n",
            "Test Set Mean Squared Error: 67.1403\n",
            "Test Set Root Mean Squared Error: 8.1939\n",
            "Test Set Mean Absolute Error: 6.6385\n",
            "Test Set Mean Absolute Percentage Error: 0.0404\n"
          ]
        }
      ],
      "source": [
        "def create_model(neurons=16, optimizer='Adam'):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=neurons, input_shape=(look_back, X_AAPL1.shape[2])))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "model = KerasRegressor(model=create_model,\n",
        "                       neurons=16,\n",
        "                       optimizer='Adam',\n",
        "                       verbose=0)\n",
        "\n",
        "\n",
        "param_grid = {'neurons': [16, 32, 64, 128, 256, 512],\n",
        "              'optimizer': ['RMSprop', 'Adam', 'AdamW', 'Nadam'],\n",
        "              'batch_size' :[16,32,64,128,256],\n",
        "              'epochs' :[60,80,100,150,200]}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs = -1)\n",
        "\n",
        "\n",
        "grid_result = grid.fit(X_AAPL1, y_AAPL1)\n",
        "\n",
        "best_model = grid_result.best_estimator_\n",
        "best_params = grid_result.best_params_\n",
        "\n",
        "y_pred = best_model.predict(X_AAPL1)\n",
        "mse = mean_squared_error(y_AAPL1, y_pred)\n",
        "rmse = root_mean_squared_error(y_AAPL1, y_pred)\n",
        "mae = mean_absolute_error(y_AAPL1, y_pred)\n",
        "mape = mean_absolute_percentage_error(y_AAPL1, y_pred)\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Test Set Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"Test Set Root Mean Squared Error: {rmse:.4f}\")\n",
        "print(f\"Test Set Mean Absolute Error: {mae:.4f}\")\n",
        "print(f\"Test Set Mean Absolute Percentage Error: {mape:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heLfV9MWbLhy"
      },
      "source": [
        "#MSFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ifskpSjoq97d"
      },
      "outputs": [],
      "source": [
        "train_MSFT = df_MSFT.iloc[:train_size]  # ข้อมูล train\n",
        "test_MSFT = df_MSFT.iloc[train_size:]  # ข้อมูล test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JWJZRhL6q91W"
      },
      "outputs": [],
      "source": [
        "X_MSFT = train_MSFT[[\"S&P500\",\"CPI\",\"Interest\",\"US_inflation_rate\", \"NASDAQ\"]]\n",
        "y_MSFT = train_MSFT[\"Stockprice_MSFT\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PhUx9a4d8gqP"
      },
      "outputs": [],
      "source": [
        "X_MSFT = scaler.fit_transform(X_MSFT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JEYRxLXScVZV"
      },
      "outputs": [],
      "source": [
        "look_back = 10\n",
        "\n",
        "X_MSFT1, y_MSFT1 = [], []\n",
        "for i in range(len(X_MSFT) - look_back):\n",
        "    X_MSFT1.append(X_MSFT[i:i + look_back])\n",
        "    y_MSFT1.append(y_MSFT[i + look_back])\n",
        "\n",
        "X_MSFT1, y_MSFT1 = np.array(X_MSFT1), np.array(y_MSFT1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IklZWmgUcVZV",
        "outputId": "a2b92b74-b1e7-46b6-db4f-363ebba6ef74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'batch_size': 16, 'epochs': 200, 'neurons': 512, 'optimizer': 'AdamW'}\n",
            "Test Set Mean Squared Error: 132.3200\n",
            "Test Set Root Mean Squared Error: 11.5030\n",
            "Test Set Mean Absolute Error: 8.8158\n",
            "Test Set Mean Absolute Percentage Error: 0.0284\n"
          ]
        }
      ],
      "source": [
        "def create_model(neurons=16, optimizer='Adam'):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=neurons, input_shape=(look_back, X_MSFT1.shape[2])))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "model = KerasRegressor(model=create_model,\n",
        "                       neurons=16,\n",
        "                       optimizer='Adam',\n",
        "                       verbose=0)\n",
        "\n",
        "\n",
        "param_grid = {'neurons': [16, 32, 64, 128, 256, 512],\n",
        "              'optimizer': ['RMSprop', 'Adam', 'AdamW', 'Nadam'],\n",
        "              'batch_size' :[16,32,64,128,256],\n",
        "              'epochs' :[60,80,100,150,200]}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs = -1)\n",
        "\n",
        "\n",
        "grid_result = grid.fit(X_MSFT1, y_MSFT1)\n",
        "\n",
        "best_model = grid_result.best_estimator_\n",
        "best_params = grid_result.best_params_\n",
        "\n",
        "y_pred = best_model.predict(X_MSFT1)\n",
        "mse = mean_squared_error(y_MSFT1, y_pred)\n",
        "rmse = root_mean_squared_error(y_MSFT1, y_pred)\n",
        "mae = mean_absolute_error(y_MSFT1, y_pred)\n",
        "mape = mean_absolute_percentage_error(y_MSFT1, y_pred)\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Test Set Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"Test Set Root Mean Squared Error: {rmse:.4f}\")\n",
        "print(f\"Test Set Mean Absolute Error: {mae:.4f}\")\n",
        "print(f\"Test Set Mean Absolute Percentage Error: {mape:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w56PKuGHbM5I"
      },
      "source": [
        "#NVDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Oz5zZalBrCX9"
      },
      "outputs": [],
      "source": [
        "train_NVDA = df_NVDA.iloc[:train_size]  # ข้อมูล train\n",
        "test_NVDA = df_NVDA.iloc[train_size:]  # ข้อมูล test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "r9JrzV8UrB_m"
      },
      "outputs": [],
      "source": [
        "X_NVDA = train_NVDA[[\"S&P500\", \"BTC\", \"CPI\", \"Gold\",\"US_inflation_rate\", \"NASDAQ\"]]\n",
        "y_NVDA = train_NVDA[\"Stockprice_NVDA\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Up2dgKyf8UA6"
      },
      "outputs": [],
      "source": [
        "X_NVDA = scaler.fit_transform(X_NVDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "eH1H3e5VcWR2"
      },
      "outputs": [],
      "source": [
        "look_back = 10\n",
        "\n",
        "X_NVDA1, y_NVDA1 = [], []\n",
        "for i in range(len(X_NVDA) - look_back):\n",
        "    X_NVDA1.append(X_NVDA[i:i + look_back])\n",
        "    y_NVDA1.append(y_NVDA[i + look_back])\n",
        "\n",
        "X_NVDA1, y_NVDA1 = np.array(X_NVDA1), np.array(y_NVDA1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KUkWSE_cWR2",
        "outputId": "31d2d04c-cc92-4606-c2df-e8f70760e987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'batch_size': 16, 'epochs': 200, 'neurons': 512, 'optimizer': 'AdamW'}\n",
            "Test Set Mean Squared Error: 4.9071\n",
            "Test Set Root Mean Squared Error: 2.2152\n",
            "Test Set Mean Absolute Error: 1.4421\n",
            "Test Set Mean Absolute Percentage Error: 0.0407\n"
          ]
        }
      ],
      "source": [
        "def create_model(neurons=16, optimizer='Adam'):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=neurons, input_shape=(look_back,X_NVDA1.shape[2])))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "model = KerasRegressor(model=create_model,\n",
        "                       neurons=16,\n",
        "                       optimizer='Adam',\n",
        "                       verbose=0)\n",
        "\n",
        "\n",
        "param_grid = {'neurons': [16, 32, 64, 128, 256, 512],\n",
        "              'optimizer': ['RMSprop', 'Adam', 'AdamW', 'Nadam'],\n",
        "              'batch_size' :[16,32,64,128,256],\n",
        "              'epochs' :[60,80,100,150,200]}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs = -1)\n",
        "\n",
        "\n",
        "grid_result = grid.fit(X_NVDA1, y_NVDA1)\n",
        "\n",
        "best_model = grid_result.best_estimator_\n",
        "best_params = grid_result.best_params_\n",
        "\n",
        "y_pred = best_model.predict(X_NVDA1)\n",
        "mse = mean_squared_error(y_NVDA1, y_pred)\n",
        "rmse = root_mean_squared_error(y_NVDA1, y_pred)\n",
        "mae = mean_absolute_error(y_NVDA1, y_pred)\n",
        "mape = mean_absolute_percentage_error(y_NVDA1, y_pred)\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Test Set Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"Test Set Root Mean Squared Error: {rmse:.4f}\")\n",
        "print(f\"Test Set Mean Absolute Error: {mae:.4f}\")\n",
        "print(f\"Test Set Mean Absolute Percentage Error: {mape:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgF9NdusbOSD"
      },
      "source": [
        "#GOOG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gOuGxqTPiK9H"
      },
      "outputs": [],
      "source": [
        "train_GOOG = df_GOOG.iloc[:train_size]  # ข้อมูล train\n",
        "test_GOOG = df_GOOG.iloc[train_size:]  # ข้อมูล test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tq-voUTqrI89"
      },
      "outputs": [],
      "source": [
        "X_GOOG = train_GOOG[[\"S&P500\", \"Gold\", \"CPI\", \"Interest\", \"UNEMPLOYMENT\", \"NASDAQ\"]]\n",
        "y_GOOG = train_GOOG[\"Stockprice_GOOGL\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nUFWaVZn8XBx"
      },
      "outputs": [],
      "source": [
        "X_GOOG = scaler.fit_transform(X_GOOG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vmzi_kf8cWvA"
      },
      "outputs": [],
      "source": [
        "look_back = 10\n",
        "\n",
        "X_GOOG1, y_GOOG1 = [], []\n",
        "for i in range(len(X_GOOG) - look_back):\n",
        "    X_GOOG1.append(X_GOOG[i:i + look_back])\n",
        "    y_GOOG1.append(y_GOOG[i + look_back])\n",
        "\n",
        "X_GOOG1, y_GOOG1 = np.array(X_GOOG1), np.array(y_GOOG1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7u2SbDqcWvB",
        "outputId": "81a24c06-e423-462f-fb47-3414f385dbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'batch_size': 16, 'epochs': 200, 'neurons': 128, 'optimizer': 'Adam'}\n",
            "Test Set Mean Squared Error: 19.4601\n",
            "Test Set Root Mean Squared Error: 4.4114\n",
            "Test Set Mean Absolute Error: 3.5231\n",
            "Test Set Mean Absolute Percentage Error: 0.0293\n"
          ]
        }
      ],
      "source": [
        "def create_model(neurons=16, optimizer='Adam'):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=neurons, input_shape=(look_back,X_GOOG1.shape[2])))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "model = KerasRegressor(model=create_model,\n",
        "                       neurons=16,\n",
        "                       optimizer='Adam',\n",
        "                       verbose=0)\n",
        "\n",
        "\n",
        "param_grid = {'neurons': [16, 32, 64, 128, 256, 512],\n",
        "              'optimizer': ['RMSprop', 'Adam', 'AdamW', 'Nadam'],\n",
        "              'batch_size' :[16,32,64,128,256],\n",
        "              'epochs' :[60,80,100,150,200]}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs = -1)\n",
        "\n",
        "\n",
        "grid_result = grid.fit(X_GOOG1, y_GOOG1)\n",
        "\n",
        "best_model = grid_result.best_estimator_\n",
        "best_params = grid_result.best_params_\n",
        "\n",
        "y_pred = best_model.predict(X_GOOG1)\n",
        "mse = mean_squared_error(y_GOOG1, y_pred)\n",
        "rmse = root_mean_squared_error(y_GOOG1, y_pred)\n",
        "mae = mean_absolute_error(y_GOOG1, y_pred)\n",
        "mape = mean_absolute_percentage_error(y_GOOG1, y_pred)\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Test Set Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"Test Set Root Mean Squared Error: {rmse:.4f}\")\n",
        "print(f\"Test Set Mean Absolute Error: {mae:.4f}\")\n",
        "print(f\"Test Set Mean Absolute Percentage Error: {mape:.4f}\")"
      ]
    }
  ]
}